# ğŸš€ STL Vision PathPlanner

<div align="center">

![Python](https://img.shields.io/badge/Python-3.8+-blue.svg?style=for-the-badge&logo=python&logoColor=white)
![YOLO](https://img.shields.io/badge/YOLOv8-Ultralytics-00FFFF.svg?style=for-the-badge&logo=yolo&logoColor=white)
![OpenCV](https://img.shields.io/badge/OpenCV-4.x-green.svg?style=for-the-badge&logo=opencv&logoColor=white)
![ROS2](https://img.shields.io/badge/ROS2-Humble-orange.svg?style=for-the-badge&logo=ros&logoColor=white)
![License](https://img.shields.io/badge/License-MIT-yellow.svg?style=for-the-badge)

<h3>ğŸ¯ Transform 3D STL Models into Real-Time Object Detection & Robotic Tool Paths</h3>

<p><i>From CAD to Camera to Robot â€” All in One Pipeline! ğŸ¤–</i></p>

[Features](#-features) â€¢ [Demo](#-demo) â€¢ [Installation](#-installation) â€¢ [Usage](#-usage) â€¢ [ROS2](#-ros2-integration) â€¢ [Contributing](#-contributing)

</div>

---

## âœ¨ What is This Magic?

**STL Vision PathPlanner** is a complete pipeline that:

1. ğŸ“¦ Takes your **3D STL model** (CAD file)
2. ğŸ¨ Generates **synthetic training images** with augmentation
3. ğŸ§  Trains a **YOLOv8 AI model** to detect your object
4. ğŸ“· Runs **real-time detection** with Intel RealSense camera
5. ğŸ›¤ï¸ Generates **robotic tool paths** around detected objects
6. ğŸ¤– Exports **ROS2-compatible YAML** for robot control

> ğŸ’¡ **No manual labeling required!** The system auto-generates labeled training data from your 3D model.

---

## ğŸ¬ Demo

<div align="center">

| Detection | Path Visualization |
|:---------:|:------------------:|
| ![Detection](https://via.placeholder.com/400x300/1a1a2e/00ff00?text=Real-Time+Detection) | ![Path](https://via.placeholder.com/400x300/1a1a2e/ff6600?text=Tool+Path+Overlay) |

</div>

---

## ğŸ”¥ Features

### ğŸ¯ Core Capabilities

| Feature | Description |
|:-------:|:------------|
| ğŸ­ **Synthetic Data Generation** | Auto-generate thousands of training images from STL |
| ğŸ§  **YOLO Training Pipeline** | One-command training with augmentation |
| ğŸ“· **RealSense Integration** | 3D coordinates + orientation from depth |
| ğŸ›¤ï¸ **6 Path Strategies** | Contour, Spiral, Zigzag, Surface, Grid, Approach |
| ğŸ”´ **Collision Avoidance** | Depth-based obstacle detection |
| ğŸ“ **ROS2 Ready** | PoseStamped YAML with quaternions |

### ğŸ® Interactive Controls

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ® KEYBOARD CONTROLS                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  p     â†’  Generate tool path            â”‚
â”‚  1-6   â†’  Switch strategy instantly     â”‚
â”‚  v     â†’  Toggle path visualization     â”‚
â”‚  r     â†’  Reload settings.yaml          â”‚
â”‚  s     â†’  Save frame                    â”‚
â”‚  +/-   â†’  Adjust confidence             â”‚
â”‚  q     â†’  Quit                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸŒ€ Path Strategies

| # | Strategy | Pattern | Best For |
|:-:|:--------:|:-------:|:---------|
| 1 | `contour` | ğŸ”µ Elliptical | Inspection, Welding |
| 2 | `approach` | ğŸ“ Pick-place | Grasping |
| 3 | `grid` | â–¦ Raster | Scanning, Coating |
| 4 | `surface` | ğŸŒŠ Depth-aware | Complex surfaces |
| 5 | `spiral` | ğŸŒ€ Inward/Out | Polishing |
| 6 | `zigzag` | âš¡ Back-forth | Coverage |

---

## ğŸ“¦ Installation

### Prerequisites

- Python 3.8+
- Intel RealSense camera (optional, webcam works too)
- NVIDIA GPU (recommended for training)

### Quick Install

```bash
# Clone the repository
git clone https://github.com/Rohit11-OG/STL-Vision-Pathplanner-.git
cd STL-Vision-Pathplanner-

# Install dependencies
pip install -r requirements.txt

# Verify installation
python main.py info
```

---

## ğŸš€ Usage

### 1ï¸âƒ£ Full Pipeline (STL â†’ Detection â†’ Path)

```bash
# Generate data, train model, run detection
python main.py full --stl your_object.stl --epochs 50
```

### 2ï¸âƒ£ Step-by-Step

```bash
# Generate synthetic training data
python main.py generate --stl bottle.stl --num-images 500

# Train the detector
python main.py train --epochs 100

# Run real-time detection with path generation
python main.py path --strategy spiral --camera 0
```

### 3ï¸âƒ£ Configuration

Edit `settings.yaml` for custom settings:

```yaml
detection:
  confidence: 0.65

path_planning:
  strategy: contour
  num_waypoints: 20
  velocity: 0.1  # m/s

visualization:
  show_path: true
```

---

## ğŸ›¤ï¸ Tool Path Output

Generated paths are saved as ROS-compatible YAML:

```yaml
header:
  frame_id: "camera_link"
  
path:
  waypoints:
    - pose:
        position: {x: 0.15, y: 0.05, z: 0.55}
        orientation: {x: 0, y: 0, z: 0.38, w: 0.92}
      velocity: 0.1
      time_from_start: {sec: 0, nanosec: 500000000}
```

---

## ğŸ¤– ROS2 Integration

### Launch Detection Node

```bash
ros2 launch stl_detector_ros2 detection.launch.py
```

### Topics

| Topic | Type | Description |
|:------|:-----|:------------|
| `/tool_path` | nav_msgs/Path | Generated path |
| `/detections` | DetectionArray | Object detections |

### Publish Path Service

```bash
ros2 service call /publish_latest_path std_srvs/srv/Trigger
```

---

## ğŸ“ Project Structure

```
STL-Vision-Pathplanner/
â”œâ”€â”€ ğŸ¯ main.py                 # CLI entry point
â”œâ”€â”€ ğŸ§  train_detector.py       # YOLO training
â”œâ”€â”€ ğŸ“· realtime_detector.py    # Detection + visualization
â”œâ”€â”€ ğŸ›¤ï¸ tool_path_planner.py    # Path generation
â”œâ”€â”€ ğŸ¨ data_generator.py       # Synthetic data
â”œâ”€â”€ âš™ï¸ config.py               # Configuration
â”œâ”€â”€ ğŸ“ settings.yaml           # User settings
â”œâ”€â”€ ğŸ¤– ros2_path_publisher.py  # ROS2 node
â””â”€â”€ ğŸ“¦ stl_detector_ros2/      # ROS2 package
```

---

## ğŸ¯ Workflow

```mermaid
graph LR
    A[ğŸ“¦ STL Model] --> B[ğŸ¨ Synthetic Images]
    B --> C[ğŸ§  YOLO Training]
    C --> D[ğŸ“· Real-time Detection]
    D --> E[ğŸ›¤ï¸ Path Generation]
    E --> F[ğŸ¤– Robot Execution]
```

---

## ğŸ› ï¸ Tech Stack

<div align="center">

| Technology | Purpose |
|:----------:|:--------|
| ğŸ Python | Core language |
| ğŸ”¥ PyTorch | Deep learning |
| ğŸ‘ï¸ YOLOv8 | Object detection |
| ğŸ“¸ OpenCV | Image processing |
| ğŸ“· RealSense | 3D camera |
| ğŸ¤– ROS2 | Robot integration |
| ğŸ¨ Trimesh | STL processing |

</div>

---

## ğŸ¤ Contributing

Contributions are welcome! 

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- [Ultralytics](https://ultralytics.com/) for YOLOv8
- [Intel RealSense](https://www.intelrealsense.com/) for depth sensing
- [ROS2](https://ros.org/) community

---

<div align="center">

### â­ Star this repo if you find it useful!

Made with â¤ï¸ by [Rohit](https://github.com/Rohit11-OG)

</div>
